# -*- coding: utf-8 -*-
"""SubTaskA-LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/186L6jCkwRftcek7OncSd65HGoAhuu7dC
"""

import os
import nltk
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import string
import re

os.chdir('/Users/amber/Documents/AIT-526/project')
os.getcwd()

"""## Step 1. Data Pre-processing
### 1.1  Extract dataset
"""

#Load dataset for models
df_english = pd.read_csv("olid-training-v1.0.tsv", sep='\t')

#Load semeval2020 test datasets
test_a_tweets = pd.read_csv("test_a_tweets.tsv", sep='\t')
test_b_tweets = pd.read_csv("test_b_tweets.tsv", sep='\t')
test_c_tweets = pd.read_csv("test_c_tweets.tsv", sep='\t')

df_english

"""### 1.2  Clean input data"""

def clean_tweet(tweet):
    '''
    removes punctuation marks, other redundant characters, words, emojis
    '''
    tweet = re.sub("(@[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)", " ", tweet).split()
    tweet = [word.lower() for word in tweet if word!='URL']
    return ' '.join(tweet)

#nltk.download('punkt')
def tokenize(tweet):
    tokenized_data = []
    for row in tweet:
        tokens = nltk.word_tokenize(row)
        tokenized_data.append(tokens)
    return tokenized_data

# remove stopwords
from nltk.corpus import stopwords
def remove_stop_words(data):
    stop_words = set(stopwords.words('english'))
    no_stop_data = []
    for row in data:
        temp = [word.lower() for word in row.split() if word.lower() not in stop_words]
        no_stop_data.extend(temp)
    return no_stop_data

# remove numbers
def remove_numbers(data):
    data_without_num = []
    for row in data:
        row_without_num = []
        for word in row:
            # Check if the token does not contain any numbers
            if not any(char.isdigit() for char in word):
                row_without_num.append(word)
        data_without_num.append(row_without_num)
    return data_without_num

# lemmatization
from nltk.stem import WordNetLemmatizer
wnl = WordNetLemmatizer()
def lemmatizer(data):
    lemmatized_data = [] #a list to store all words after lemmatization
    for row in data:
        row_lemmatized = [wnl.lemmatize(word) for word in row] #lemmatize by row
        lemmatized_data.append(row_lemmatized)
    return lemmatized_data

# clean subtask_A
df_english['tweet_cleaned'] = df_english['tweet'].apply(clean_tweet)

# Tokenize data
df_english['tweet_tokenization'] = tokenize(df_english['tweet_cleaned'])

# remove stopwords
df_english['tweet_remove_stopwords'] = df_english['tweet_tokenization'].apply(remove_stop_words)

# remove numbers
df_english['tweet_remove_numbers'] = remove_numbers(df_english['tweet_remove_stopwords'])

# lemmatization
df_english['tweet_final'] = lemmatizer(df_english['tweet_remove_numbers'])

df_english[['tweet', 'tweet_cleaned', 'tweet_tokenization', 'tweet_remove_stopwords', 'tweet_remove_numbers', 'tweet_final']]

# final dataset
refined_df = df_english[['tweet_final', 'subtask_a', 'subtask_b', 'subtask_c']]
#refined_df.to_csv('refined_df.csv', index=False)

# extract dataset for subtasks
subtask_A = refined_df[refined_df['subtask_a'].notna()][['tweet_final', 'subtask_a']]
subtask_B = refined_df[refined_df['subtask_b'].notna()][['tweet_final', 'subtask_b']]
subtask_C = refined_df[refined_df['subtask_c'].notna()][['tweet_final', 'subtask_c']]
subtask_A

"""### 1.3  Analyze output dataset"""

import matplotlib.pyplot as plt
plt.figure(figsize = (12,4))
#1
plt.subplot(131)
subtask_A['subtask_a'].value_counts().plot(kind='bar')
plt.xticks(rotation=0)
plt.title("Distribution of labels in subtask A");
#2
plt.subplot(132)
subtask_B['subtask_b'].value_counts().plot(kind='bar')
plt.xticks(rotation=0)
plt.title("Distribition of labels in subtask B");
#3
plt.subplot(133)
subtask_C['subtask_c'].value_counts().plot(kind='bar')
plt.xticks(rotation=0)
plt.title("Distribition of labels in subtask C");

"""### From the visualization: The output labels exhibit an imbalance in the datasets

### 1.4  Split data and over sample training data
"""

#!pip install imblearn

# Over / under - sampling
from sklearn.model_selection import train_test_split
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler

# make a function to sampling
def resample_dataset(df, target_column, method = 'over', random_state=24, test_size=0.3):
    X = df.drop(target_column, axis=1)
    y = df[target_column]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

    if method == 'under':
        sampler = RandomUnderSampler(random_state=random_state)
    elif method == 'over':
        sampler = RandomOverSampler(random_state=random_state)
    else:
        raise ValueError("Invalid resampling method. Use 'under' or 'over'.")

    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)
    resampled_df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name=target_column)], axis=1)

    return resampled_df, X_train, X_test, y_train, y_test

# split into 70% training and 30% testing, over sampling training data
resampled_df_A, X_train_A, X_test_A, y_train_A, y_test_A = resample_dataset(df=subtask_A, target_column='subtask_a')
resampled_df_B, X_train_B, X_test_B, y_train_B, y_test_B = resample_dataset(df=subtask_B, target_column='subtask_b')
resampled_df_C, X_train_C, X_test_C, y_train_C, y_test_C = resample_dataset(df=subtask_C, target_column='subtask_c')

# training data
plt.figure(figsize = (12,4))
#1
plt.subplot(131)
resampled_df_A['subtask_a'].value_counts().plot(kind='bar')
plt.xticks(rotation=0)
plt.title("Labels in training of resampled subtask-A");
#2
plt.subplot(132)
resampled_df_B['subtask_b'].value_counts().plot(kind='bar')
plt.xticks(rotation=0)
plt.title("Labels in training of resampled subtask-B");
#3
plt.subplot(133)
resampled_df_C['subtask_c'].value_counts().plot(kind='bar')
plt.xticks(rotation=0)
plt.title("Labels in training of resampled subtask-C");
plt.tight_layout()

"""## Step 2. Baseline: Bag-of-Words model
### The purpose of creating a baseline BoW model is to establish a simple and interpretable model that can serve as a starting point for comparison with more sophisticated models.
"""

X_train_A

# BoW model by Random Forest
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

def train_bow_model(X_train, X_test, y_train, y_test, random_state=None):
    vectorizer = CountVectorizer(min_df=1)
    X_train_bow = vectorizer.fit_transform(X_train['tweet_final'].apply(lambda x: ' '.join(x)))
    X_test_bow = vectorizer.transform(X_test['tweet_final'].apply(lambda x: ' '.join(x)))
    y_train = y_train.values
    y_test = y_test.values

    # Create a classifier (Random Forest)
    classifier = RandomForestClassifier(random_state=random_state)
    classifier.fit(X_train_bow, y_train)
    predictions = classifier.predict(X_test_bow)

    # Evaluate the model
    accuracy = accuracy_score(y_test, predictions)
    classification_rep = classification_report(y_test, predictions)

    print(f"Accuracy: {accuracy:.4f}")
    print("Classification Report:\n", classification_rep)

# Bag-of-Words model for subtask A
train_bow_model(X_train_A, X_test_A, y_train_A, y_test_A, random_state=24)

# Bag-of-Words model for subtask B
train_bow_model(X_train_B, X_test_B, y_train_B, y_test_B, random_state=24)

# Bag-of-Words model for subtask C
train_bow_model(X_train_C, X_test_C, y_train_C, y_test_C, random_state=24)

"""## Step 3. Subtasks - LSTM
### 3.1 LSTM model for subtask A
### 3.1.1 train LSTM model for subtask A
"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer()
tokenizer.fit_on_texts(X_train_A['tweet_final'])

wordidx = tokenizer.word_index
V = len(wordidx)
print('The size of datatset vocab is: ', V)

# Convert text data to sequences of integers
train_sequences_A = tokenizer.texts_to_sequences(X_train_A['tweet_final'])
test_sequences_A = tokenizer.texts_to_sequences(X_test_A['tweet_final'])

# Padding sequences to the same length
pad_train_A = pad_sequences(train_sequences_A)
pad_test_A = pad_sequences(test_sequences_A, maxlen=pad_train_A.shape[1])

# Display the length of the padded sequences
T = pad_train_A.shape[1]
print('The length of the sequences after padding:', T)

# Covert labels to numbers
label_mapping = {"NOT": 0, "OFF": 1}

# Apply the mapping to the original labels
y_train_encoded_A = y_train_A.map(label_mapping).values
y_test_encoded_A = y_test_A.map(label_mapping).values

y_test_encoded_A

from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, GlobalMaxPooling1D
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dropout
from tensorflow.keras.regularizers import l1

D = 3
M = 3

# Assuming word_index is obtained from the Tokenizer
V = len(wordidx)

i = Input(shape=(T,))
x = Embedding(V + 1, D)(i)
x = LSTM(M, return_sequences=True)(x)
x = GlobalMaxPooling1D()(x)
#x = Dropout(0.3)(x)
x = Dense(6, activation='relu', kernel_regularizer=l1(0.02))(x)
#x = Dropout(0.5)(x)
x = Dense(1, activation='sigmoid')(x)

model = Model(i, x)

# compiling the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# training the model
r = model.fit(pad_train_A, y_train_encoded_A, validation_data=(pad_test_A, y_test_encoded_A), epochs=5)

plt.plot(r.history['accuracy'], label= 'accuracy')
plt.plot(r.history['val_accuracy'], label='val_accuracy')
plt.legend()

y_pred = model.predict(pad_test_A)
y_pred_classes = (y_pred > 0.5).astype(int)

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix

precision = precision_score(y_test_encoded_A, y_pred_classes)
recall = recall_score(y_test_encoded_A, y_pred_classes)
f1 = f1_score(y_test_encoded_A, y_pred_classes)
accuracy = accuracy_score(y_test_encoded_A, y_pred_classes)
conf_matrix = confusion_matrix(y_test_encoded_A, y_pred_classes)


print("Accuracy: %.2f" % accuracy)
print("Precision: %.2f" % precision)
print("Recall: %.2f" % recall)
print("F1 Score: %.2f" % f1)

conf_matrix

# compare to te baseline model. LSTM has higher recall

"""### 3.1.2 Test OLID data for subtask A"""

olid_testset_a = pd.read_csv("testset-levela.tsv", sep='\t')
olid_label_a = pd.read_csv("labels-levela.csv", header=None)

olid_testset_a

# clean olid_testset_A
olid_testset_a['tweet_cleaned'] = olid_testset_a['tweet'].apply(clean_tweet)
# Tokenize data
olid_testset_a['tweet_tokenization'] = tokenize(olid_testset_a['tweet_cleaned'])
# remove stopwords
olid_testset_a['tweet_remove_stopwords'] = olid_testset_a['tweet_tokenization'].apply(remove_stop_words)
#remove numbers
olid_testset_a['tweet_remove_numbers'] = remove_numbers(olid_testset_a['tweet_remove_stopwords'])
# lemmatization
olid_testset_a['tweet_final'] = lemmatizer(olid_testset_a['tweet_remove_numbers'])
olid_testset_a

# final test_set_a
refined_test_a = olid_testset_a[['tweet_final']]

# Padding sequences to the same length
test_sequences_a = tokenizer.texts_to_sequences(refined_test_a['tweet_final'])
pad_test_a = pad_sequences(test_sequences_a, maxlen=pad_train_A.shape[1])
T = pad_test_a.shape[1]
print('The length of the sequences after padding:', T)

#olid_label_a[1]

# Test_a label
test_label_encoded_a = olid_label_a[1].map(label_mapping).values

# LSTM
y_pred_testa = model.predict(pad_test_a)
y_pred_testa_classes = (y_pred_testa > 0.5).astype(int)

precision_a = precision_score(test_label_encoded_a, y_pred_testa_classes)
recall_a = recall_score(test_label_encoded_a, y_pred_testa_classes)
f1_a = f1_score(test_label_encoded_a, y_pred_testa_classes)
accuracy_a = accuracy_score(test_label_encoded_a, y_pred_testa_classes)

print("Accuracy: %.2f" % accuracy_a)
print("Precision: %.2f" % precision_a)
print("Recall: %.2f" % recall_a)
print("F1 Score: %.2f" % f1_a)

"""### 3.1.3 Test SOLID data for subtask A"""

solid_testset_a = pd.read_csv("test_a_tweets.tsv", sep='\t')
solid_label_a = pd.read_csv("test_a_labels.csv", header=None)



# clean solid_testset_A
solid_testset_a['tweet_cleaned'] = solid_testset_a['tweet'].apply(clean_tweet)
# Tokenize data
solid_testset_a['tweet_tokenization'] = tokenize(solid_testset_a['tweet_cleaned'])
# remove stopwords
solid_testset_a['tweet_remove_stopwords'] = solid_testset_a['tweet_tokenization'].apply(remove_stop_words)
#remove numbers
solid_testset_a['tweet_remove_numbers'] = remove_numbers(solid_testset_a['tweet_remove_stopwords'])
# lemmatization
solid_testset_a['tweet_final'] = lemmatizer(solid_testset_a['tweet_remove_numbers'])
solid_testset_a

# final test_set_a
refined_stest_a = solid_testset_a[['tweet_final']]

# Padding sequences to the same length
stest_sequences_a = tokenizer.texts_to_sequences(refined_stest_a['tweet_final'])
pad_stest_a = pad_sequences(stest_sequences_a, maxlen=pad_train_A.shape[1])
T = pad_stest_a.shape[1]
print('The length of the sequences after padding:', T)

# stest_a label
stest_label_encoded_a = solid_label_a[1].map(label_mapping).values

# LSTM
y_pred_stesta = model.predict(pad_stest_a)
y_pred_stesta_classes = (y_pred_stesta > 0.5).astype(int)

# solid_test_a
precision_sa = precision_score(stest_label_encoded_a, y_pred_stesta_classes)
recall_sa = recall_score(stest_label_encoded_a, y_pred_stesta_classes)
f1_sa = f1_score(stest_label_encoded_a, y_pred_stesta_classes)
accuracy_sa = accuracy_score(stest_label_encoded_a, y_pred_stesta_classes)

print("Accuracy: %.2f" % accuracy_sa)
print("Precision: %.2f" % precision_sa)
print("Recall: %.2f" % recall_sa)
print("F1 Score: %.2f" % f1_sa)

"""### 3.1.4 Test extended test data from SOLID data for subtask A

"""

# load dataset
extend_easy = pd.read_csv("test_a_labels_easy.csv")
extend_hard = pd.read_csv("test_a_labels_hard.csv")
extend_tweet = pd.read_csv("test_a_tweets_all.tsv", sep='\t')

# join dataset
df_extend_easy = pd.merge(extend_easy, extend_tweet, on='id', how='left')
df_extend_hard = pd.merge(extend_hard, extend_tweet, on='id', how='left')

#df_extend_hard

# clean df_extend_easy
df_extend_easy['tweet_cleaned'] = df_extend_easy['tweet'].apply(clean_tweet)
# Tokenize data
df_extend_easy['tweet_tokenization'] = tokenize(df_extend_easy['tweet_cleaned'])
# remove stopwords
df_extend_easy['tweet_remove_stopwords'] = df_extend_easy['tweet_tokenization'].apply(remove_stop_words)
#remove numbers
df_extend_easy['tweet_remove_numbers'] = remove_numbers(df_extend_easy['tweet_remove_stopwords'])
# lemmatization
df_extend_easy['tweet_final'] = lemmatizer(df_extend_easy['tweet_remove_numbers'])
extend_easy_a = df_extend_easy[['id', 'tweet_final', 'label']]
extend_easy_a

# clean df_extend_hard
df_extend_hard['tweet_cleaned'] = df_extend_hard['tweet'].apply(clean_tweet)
# Tokenize data
df_extend_hard['tweet_tokenization'] = tokenize(df_extend_hard['tweet_cleaned'])
# remove stopwords
df_extend_hard['tweet_remove_stopwords'] = df_extend_hard['tweet_tokenization'].apply(remove_stop_words)
#remove numbers
df_extend_hard['tweet_remove_numbers'] = remove_numbers(df_extend_hard['tweet_remove_stopwords'])
# lemmatization
df_extend_hard['tweet_final'] = lemmatizer(df_extend_hard['tweet_remove_numbers'])
extend_hard_a = df_extend_hard[['id', 'tweet_final', 'label']]
extend_hard_a

# Padding sequences to the same length
easy_sequences_a = tokenizer.texts_to_sequences(extend_easy_a['tweet_final'])
pad_easy_a = pad_sequences(easy_sequences_a, maxlen=pad_train_A.shape[1])
T = pad_easy_a.shape[1]
print('The length of the sequences after padding:', T)

hard_sequences_a = tokenizer.texts_to_sequences(extend_hard_a['tweet_final'])
pad_hard_a = pad_sequences(hard_sequences_a, maxlen=pad_train_A.shape[1])
T = pad_hard_a.shape[1]
print('The length of the sequences after padding:', T)

# encode label
easy_label_encoded_a = extend_easy_a['label'].map(label_mapping).values
hard_label_encoded_a = extend_hard_a['label'].map(label_mapping).values

# LSTM - easy
y_pred_easy = model.predict(pad_easy_a)
y_pred_easy_classes = (y_pred_easy > 0.5).astype(int)

# LSTM - hard
y_pred_hard = model.predict(pad_hard_a)
y_pred_hard_classes = (y_pred_hard > 0.5).astype(int)

# results for easy_a
precision_ea = precision_score(easy_label_encoded_a, y_pred_easy_classes)
recall_ea = recall_score(easy_label_encoded_a, y_pred_easy_classes)
f1_ea = f1_score(easy_label_encoded_a, y_pred_easy_classes)
accuracy_ea = accuracy_score(easy_label_encoded_a, y_pred_easy_classes)

print("Accuracy: %.2f" % accuracy_ea)
print("Precision: %.2f" % precision_ea)
print("Recall: %.2f" % recall_ea)
print("F1 Score: %.2f" % f1_ea)

# results for hard_a
precision_ha = precision_score(hard_label_encoded_a, y_pred_hard_classes)
recall_ha = recall_score(hard_label_encoded_a, y_pred_hard_classes)
f1_ha = f1_score(hard_label_encoded_a, y_pred_hard_classes)
accuracy_ha = accuracy_score(hard_label_encoded_a, y_pred_hard_classes)

print("Accuracy: %.2f" % accuracy_ha)
print("Precision: %.2f" % precision_ha)
print("Recall: %.2f" % recall_ha)
print("F1 Score: %.2f" % f1_ha)

